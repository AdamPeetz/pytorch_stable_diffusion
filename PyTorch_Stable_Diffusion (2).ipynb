{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VZ2B9FliZl7D",
        "outputId": "eeb6d963-854c-4e95-a17b-f9c4eead9e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/899.7 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:27\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q diffusers transformers xformers accelerate\n",
        "!pip install -q numpy scipy ftfy Pillow\n",
        "#!pip install super-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MSBaqb2Zraz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "from IPython import display as IPdisplay\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers import (\n",
        "    DDIMScheduler,\n",
        "    PNDMScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    DPMSolverMultistepScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        ")\n",
        "from transformers import logging\n",
        "import glob\n",
        "\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_W3JDRZys3"
      },
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LGVP-1rKZ2uJ"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, steps_offset=1)\n",
        "\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    scheduler=scheduler,\n",
        "    torch_dtype=torch.float32,\n",
        "    safety_checker = None,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibUlVQywaHYL"
      },
      "outputs": [],
      "source": [
        "# efficiency settings\n",
        "pipe.enable_model_cpu_offload()\n",
        "pipe.unet.to(memory_format=torch.channels_last)\n",
        "pipe.vae.enable_slicing()\n",
        "pipe.vae.enable_tiling()\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXEIqzK1aTqN"
      },
      "outputs": [],
      "source": [
        "# The seed is set to \"None\", because we want different results each time we run the generation.\n",
        "seed = 0\n",
        "\n",
        "if seed is not None:\n",
        "    generator = torch.manual_seed(seed)\n",
        "else:\n",
        "    generator = None\n",
        "\n",
        "# The guidance scale is set to its normal range (7 - 10).\n",
        "guidance_scale = 7\n",
        "\n",
        "# How long should the thing bake for\n",
        "num_inference_steps = 120\n",
        "\n",
        "\n",
        "# I would not recommend less than 512 on either dimension. This is because this model was trained on 512x512 image resolution.\n",
        "height = 960\n",
        "width = 512\n",
        "\n",
        "latents = torch.randn(\n",
        "    (1, pipe.unet.config.in_channels, height // 8, width // 8),\n",
        "    generator=generator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvl4TQywT_Gx"
      },
      "outputs": [],
      "source": [
        "def generate_single_image(positive_prompt_embeds, negative_prompt_embeds, height, width, num_inference_steps, generator, latents):\n",
        "  image = pipe(\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_images_per_prompt=1,\n",
        "                prompt_embeds=positive_prompt_embeds,\n",
        "                negative_prompt_embeds=negative_prompt_embeds,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=generator,\n",
        "                latents=latents,\n",
        "                     ).images\n",
        "  return image\n",
        "\n",
        "def plot_images(images):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBPu2WkGQJEm"
      },
      "outputs": [],
      "source": [
        "# The text prompt that describes the desired output image.\n",
        "prompt_one =  \"a massive lush alien planet seen from deep space, emerald oceans and turquoise seas, vast swirling cloud systems, glowing auroras wrapping the poles, dense green continents with golden coastlines, soft sunlight illuminating the atmosphere, cinematic wide-angle view, ultra-detailed planetary textures, realistic light scattering, astrophotography style, NASA-quality realism, 8k resolution, epic scale, serene and majestic\"\n",
        "prompt_two =  \"a colossal volcanic planet floating in outer space, cracked obsidian surface with flowing lava rivers, fiery magma glowing through tectonic fractures, thick ash clouds and sulfur storms, intense red and orange color palette, dramatic rim lighting, high contrast shadows, ultra-realistic planetary geology, extreme detail, cinematic sci-fi realism, deep space background with distant stars\"\n",
        "prompt_three = \"a frozen exoplanet viewed from orbit, vast ice-covered surface with jagged glaciers and crystalline ice plates, pale blue and white tones, thin misty atmosphere, soft reflected starlight, subtle cloud bands, extreme planetary scale, hyper-realistic textures, astrophysical accuracy, calm and mysterious mood, ultra-sharp focus, space photography\"\n",
        "prompt_four = \"a massive exotic gas planet in outer space, swirling atmospheric bands of violet, cyan, and amber, luminous storms and massive cyclones, glowing upper atmosphere, smooth volumetric clouds, dramatic lighting, ultra-detailed atmospheric physics, deep space backdrop, cinematic composition, breathtaking scale, realistic sci-fi art, 8k clarity\"\n",
        "negative_prompt = \"low resolution, blurry, flat lighting, overexposed, underexposed, washed out colors, dull composition, visible pixels, jpeg artifacts, noisy image, cartoon style, anime, fantasy illustration, hand-drawn, text, watermark, logo, frame, border, distorted planet shape, unrealistic proportions, duplicated planets, low detail surface, messy clouds\"\n",
        "\n",
        "def generate_prompt_vector(prompt):\n",
        "  prompt_tokens = pipe.tokenizer(prompt,\n",
        "    padding=\"max_length\",\n",
        "    max_length=pipe.tokenizer.model_max_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",)\n",
        "\n",
        "  prompt_embeds = pipe.text_encoder(prompt_tokens.input_ids.to(device))[0]\n",
        "\n",
        "  return prompt_embeds\n",
        "\n",
        "prompt_one_embeds = generate_prompt_vector(prompt_one)\n",
        "prompt_two_embeds = generate_prompt_vector(prompt_two)\n",
        "prompt_three_embeds = generate_prompt_vector(prompt_three)\n",
        "prompt_four_embeds = generate_prompt_vector(prompt_four)\n",
        "negative_prompt_embeds = generate_prompt_vector(negative_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_m_-Yx9HSEZ"
      },
      "outputs": [],
      "source": [
        "image = generate_single_image(prompt_one_embeds, negative_prompt_embeds, height, width, num_inference_steps, generator, latents)\n",
        "plot_images(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmX8dUQkHRwq"
      },
      "outputs": [],
      "source": [
        "image = generate_single_image(prompt_two_embeds, negative_prompt_embeds, height, width, num_inference_steps, generator, latents)\n",
        "plot_images(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfGyMrA9Q4IC"
      },
      "outputs": [],
      "source": [
        "image = generate_single_image(prompt_three_embeds, negative_prompt_embeds, height, width, num_inference_steps, generator, latents)\n",
        "plot_images(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Acu7mX7JQ4YX"
      },
      "outputs": [],
      "source": [
        "image = generate_single_image(prompt_four_embeds, negative_prompt_embeds, height, width, num_inference_steps, generator, latents)\n",
        "plot_images(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iptSejXBS7iR"
      },
      "outputs": [],
      "source": [
        "def slerp(t, v0, v1, DOT_THRESHOLD=0.9995):\n",
        "    v0 = v0.detach().cpu().numpy()\n",
        "    v1 = v1.detach().cpu().numpy()\n",
        "\n",
        "    #calculate dot product of vectors\n",
        "    dot = np.sum(v0 * v1 / (np.linalg.norm(v0) * np.linalg.norm(v1)))\n",
        "    #if transformation would not be meaningful, do linear interpolation\n",
        "    if np.abs(dot) > DOT_THRESHOLD:\n",
        "        v2 = (1 - t) * v0 + t * v1\n",
        "    # otherwise, spheical interpolate\n",
        "    else:\n",
        "        theta_0 = np.arccos(dot)\n",
        "        sin_theta_0 = np.sin(theta_0)\n",
        "        theta_t = theta_0 * t\n",
        "        sin_theta_t = np.sin(theta_t)\n",
        "        s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
        "        s1 = sin_theta_t / sin_theta_0\n",
        "        v2 = s0 * v0 + s1 * v1\n",
        "\n",
        "        v2 = torch.tensor(v2)\n",
        "\n",
        "    return v2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XHCRRLDdQQif"
      },
      "outputs": [],
      "source": [
        "num_interpolation_steps = 60\n",
        "\n",
        "interpolation_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, num_interpolation_steps)):\n",
        "    interpolation_list.append(slerp(float(t), prompt_one_embeds, prompt_two_embeds))\n",
        "for _, t in enumerate(np.linspace(0, 1, num_interpolation_steps)):\n",
        "    interpolation_list.append(slerp(float(t), prompt_two_embeds, prompt_three_embeds))\n",
        "for _, t in enumerate(np.linspace(0, 1, num_interpolation_steps)):\n",
        "    interpolation_list.append(slerp(float(t), prompt_three_embeds, prompt_four_embeds))\n",
        "for _, t in enumerate(np.linspace(0, 1, num_interpolation_steps)):\n",
        "    interpolation_list.append(slerp(float(t), prompt_four_embeds, prompt_one_embeds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpzEji3IRadE"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "# Disable image generation progress bar, we'll display our own\n",
        "pipe.set_progress_bar_config(disable=True)\n",
        "print(range(len(interpolation_list)))\n",
        "for batch in tqdm(range(len(interpolation_list))):\n",
        "  images.append(pipe(\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_images_per_prompt=1,\n",
        "                prompt_embeds=interpolation_list[batch],\n",
        "                negative_prompt_embeds=negative_prompt_embeds,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=generator,\n",
        "                latents=latents,\n",
        "                     ).images\n",
        "\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKa3VWaMacwX"
      },
      "outputs": [],
      "source": [
        "def glob_save_images(base_directory, image_library, image_counter):\n",
        "  file_count = len(image_library)\n",
        "  globbed_dir_num = int((file_count/100)+1)\n",
        "  glob_file = 0\n",
        "  for flc in range(0, globbed_dir_num):\n",
        "      os.makedirs(base_directory + \"%05d\" % (flc+1), exist_ok=True)\n",
        "  for idx in tqdm(range(len(image_library))):\n",
        "    if idx  >= 0 and idx <= 100:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05s.png\" % ((glob_file+1), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 101 and idx <= 200:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+2), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 201 and idx <= 300:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+3),( image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 301 and idx <= 400:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+4), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 401 and idx <= 500:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+5), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 501 and idx <= 600:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+6), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 601 and idx <= 700:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+7), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 701 and idx <= 800:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+8), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 801 and idx <= 900:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+9), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 901 and idx <= 1000:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+10), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 1001 and idx <= 1100:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+11), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU74yKyea0LO"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "base_directory = '/content/gdrive/My Drive/stable_diffusion/'\n",
        "glob_save_images(base_directory, images, counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0oOWANYg9to"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2Hc_QhugdrV"
      },
      "outputs": [],
      "source": [
        "image_base_folder = '/content/gdrive/My Drive/stable_diffusion/' # make sure to use your folder\n",
        "file_count = len(os.listdir(image_base_folder))\n",
        "print(file_count)\n",
        "\n",
        "video_name = 'test_thousands.avi'\n",
        "os.chdir(\"/content/gdrive/My Drive/stable_diffusion_outputs/\")\n",
        "\n",
        "image_locations = []\n",
        "for dir in range(1, file_count+1):\n",
        "  for image in os.listdir(image_base_folder + \"%05d/\" % (dir)):\n",
        "    if image.endswith(\".jpg\") or image.endswith(\".jpeg\") or image.endswith(\"png\"):\n",
        "      image_locations.append(image_base_folder + \"%05d/\" % (dir) + image)\n",
        "\n",
        "images = [img for img in image_locations\n",
        "              if img.endswith(\".jpg\") or\n",
        "                 img.endswith(\".jpeg\") or\n",
        "                 img.endswith(\"png\")]\n",
        "frame = cv2.imread(images[0])\n",
        "\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "video = cv2.VideoWriter(video_name, fourcc, 4,(width, height))\n",
        "\n",
        "for image in images:\n",
        "    video.write(cv2.imread(image))\n",
        "\n",
        "video.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRySuW2TiHg6"
      },
      "outputs": [],
      "source": [
        "#import cv2\n",
        "#import numpy as np\n",
        "#video_path = \"/content/gdrive/My Drive/stable_diffusion_outputs/test_thousands.avi\"\n",
        "#cap = cv2.VideoCapture(video_path)\n",
        "#ret = True\n",
        "#frames = []\n",
        "#while ret:\n",
        "#    ret, img = cap.read()\n",
        "#    if ret:\n",
        "#      recolored_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#      frames.append(recolored_img)\n",
        "#\n",
        "#video = np.stack(frames, axis=0)\n",
        "#\n",
        "#import gc\n",
        "#from super_image import EdsrModel, ImageLoader\n",
        "#model = EdsrModel.from_pretrained('eugenesiow/edsr-base', scale=2)\n",
        "#\n",
        "#images_upscaled = []\n",
        "#with torch.no_grad():\n",
        "#  for frame in tqdm(range(len(video))):\n",
        "#    frame_float = video[frame].astype(np.float32)\n",
        "#    image_tensor = torch.from_numpy(frame_float)\n",
        "#    image_tensor = image_tensor.permute(2, 0, 1)\n",
        "#    upscale_image = model(image_tensor)\n",
        "#    upscale_image = upscale_image.permute(1, 2, 0)\n",
        "#    upscale_image = upscale_image.cpu().numpy()\n",
        "#    upscale_image = cv2.cvtColor(upscale_image, cv2.COLOR_RGB2BGR)\n",
        "#    images_upscaled.append(upscale_image)\n",
        "#    del upscale_image\n",
        "#    del image_tensor\n",
        "#    del frame_float\n",
        "#    gc.collect()\n",
        "#    torch.cuda.empty_cache()\n",
        "#\n",
        "#counter = 0\n",
        "#base_directory = '/content/gdrive/My Drive/upscaled_images/'\n",
        "#glob_save_images(base_directory, images_upscaled, counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV_iNkKEQXJ7"
      },
      "outputs": [],
      "source": [
        "#del images_upscaled\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AOuSBLSihQT"
      },
      "outputs": [],
      "source": [
        "#image_base_folder = '/content/gdrive/My Drive/upscaled_images/' # make sure to use your folder\n",
        "#file_count = len(os.listdir(image_base_folder))\n",
        "#print(file_count)\n",
        "\n",
        "#video_name = 'test_thousands_upscaled.avi'\n",
        "#os.chdir(\"/content/gdrive/My Drive/stable_diffusion_outputs/\")\n",
        "\n",
        "#image_locations = []\n",
        "#for dir in range(1, file_count+1):\n",
        "#  for image in os.listdir(image_base_folder + \"%05d/\" % (dir)):\n",
        "#    if image.endswith(\".jpg\") or image.endswith(\".jpeg\") or image.endswith(\"png\"):\n",
        "#      image_locations.append(image_base_folder + \"%05d/\" % (dir) + image)\n",
        "\n",
        "#images = [img for img in image_locations\n",
        "#              if img.endswith(\".jpg\") or\n",
        "#                 img.endswith(\".jpeg\") or\n",
        "#                 img.endswith(\"png\")]\n",
        "\n",
        "#frame = cv2.imread(images[0])\n",
        "\n",
        "#height, width, layers = frame.shape\n",
        "\n",
        "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "#video = cv2.VideoWriter(video_name, fourcc, 34,(width, height))\n",
        "\n",
        "#for image in images:\n",
        "#    video.write(cv2.imread(image))\n",
        "\n",
        "#video.release()  # releasing the video generated\n",
        "\n",
        "#cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dyrTOjN5a4l"
      },
      "outputs": [],
      "source": [
        "fileList = glob.glob('/content/gdrive/My Drive/stable_diffusion/*/*')\n",
        "print(\"Number of files removed \",len(fileList))\n",
        "\n",
        "for filePath in fileList:\n",
        "  os.remove(filePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCltIXbKit-x"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}